read.vectors("./w2vModel.bin")
nearest_to(model,model[["냉장고"]], 20)
model
dist(model)
dist(model)
temp = dist(model)
head(temp)
temp = cosineSimilarity(model)
temp = cosineDist(model)
temp = cosineDist(model,model)
View(temp)
temp[temp < 0.1] = 0
View(temp)
temp = cosineDist(model,model)
View(temp)
temp[temp < 0.5] = 0
net = network(temp, directed = FALSE)
library(igraph)
library(network)
library(sna)
library(ggplot2)
library(GGally)
library(extrafont)
net = network(temp, directed = FALSE)
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
set.edge.value(net, "edgeSize", cor_termW * 2)
set.edge.value(net, "edgeSize", temp * 2)
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
temp = cosineDist(model,model)
temp[temp < 0.9] = 0
net = network(temp, directed = FALSE)
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
set.edge.value(net, "edgeSize", temp * 2)
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
temp = cosineDist(model,model)
#Edge 개수 조절하기
temp[temp < 0.9] = 0
# Network Map을 그리기 위한 객체 만들기
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 2)
set.edge.value(net, "edgeSize", temp)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
View(temp)
temp = cosineDist(model,model)
#Edge 개수 조절하기
temp[temp < 1.1] = 0
# Network Map을 그리기 위한 객체 만들기
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 2)
set.edge.value(net, "edgeSize", temp)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
temp = cosineDist(model,model)
#Edge 개수 조절하기
temp[temp < 1.1] = 0
# Network Map을 그리기 위한 객체 만들기
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 2)
set.edge.value(net, "edgeSize", temp*0.9)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
#word2vec Train용 TXT파일 만들기
write.table(targetData$parsedContent,file = "./trainTxt.txt", row.names = FALSE, col.names = FALSE, quote = F)
#모델 Training
model = train_word2vec("./trainTxt.txt", output_file = "w2vModel.bin",
threads=3, vectors=100, force = T)
read.vectors("./w2vModel.bin")
temp = cosineDist(model,model)
#Edge 개수 조절하기
temp[temp < 1.1] = 0
# Network Map을 그리기 위한 객체 만들기
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 2)
set.edge.value(net, "edgeSize", temp*0.9)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
temp = cosineDist(model,model)
colSums(temp)
colSums(temp) > 200
colSums(temp)[1]
colSums(temp)[2]
colSums(temp)[colSums(temp)>0]
colSums(temp)[colSums(temp)<100]
colSums(temp)[colSums(temp)<200]
temp[temp < 1.1] = 0
colSums(temp)[colSums(temp)<200]
colSums(temp)[colSums(temp) = 0]
colSums(temp)[colSums(temp) == 0]
temp = cosineDist(model,model)
temp[temp < 1.1] = 0
temp = temp[,colSums(temp)!=0]
# Network Map을 그리기 위한 객체 만들기
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 2)
set.edge.value(net, "edgeSize", temp*0.9)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
colSums(temp)[colSums(temp) == 0]
temp = cosineDist(model,model)
#Edge 개수 조절하기
temp[temp < 1.1] = 0
colSums(temp)[colSums(temp) == 0]
colSums(temp)[rowSums(temp) == 0]
temp = cosineDist(model,model)
temp[temp < 1.1] = 0
temp = cosineDist(model,model)
temp[temp < 1.1] = 0
temp = temp[,colSums(temp)!=0]
temp = temp[rowSums(temp)!=0,]
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 2)
set.edge.value(net, "edgeSize", temp*0.9)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
char(temp)
temp = cosineDist(model,model)
colnames(temp)
colnames(model)
temp = cosineDist(model,model)
rownames(temp)
char(rownames(temp))
nchar(rownames(temp))
temp = cosineDist(model,model)
temp = cosineDist(model,model)
temp = temp[nchar(rownames(temp)) > 1, nchar(colnames(temp)) > 1]
temp[temp < 1] = 0
temp = temp[,colSums(temp)!=0]
temp = temp[rowSums(temp)!=0,]
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 2)
set.edge.value(net, "edgeSize", temp*0.9)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
temp = cosineDist(model,model)
temp = temp[nchar(rownames(temp)) > 1, nchar(colnames(temp)) > 1]
temp
temp[temp < 1] = 0
temp = temp[,colSums(temp)!=0]
temp = temp[rowSums(temp)!=0,]
#단어간 코사인 거리 구하기
temp = cosineDist(model,model)
#한글자 단어 삭제하기
temp = temp[nchar(rownames(temp)) > 1, nchar(colnames(temp)) > 1]
#Edge 개수 조절하기
temp[temp < 1.2] = 0
#Node 개수 조절하기 (0인 값 제외)
temp = temp[,colSums(temp)!=0]
temp = temp[rowSums(temp)!=0,]
# Network Map을 그리기 위한 객체 만들기
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 2)
set.edge.value(net, "edgeSize", temp*0.9)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
#단어간 코사인 거리 구하기
temp = cosineDist(model,model)
#한글자 단어 삭제하기
temp = temp[nchar(rownames(temp)) > 1, nchar(colnames(temp)) > 1]
#Edge 개수 조절하기
temp[temp < 1.1] = 0
#Node 개수 조절하기 (0인 값 제외)
temp = temp[,colSums(temp)!=0]
temp = temp[rowSums(temp)!=0,]
# Network Map을 그리기 위한 객체 만들기
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 2)
set.edge.value(net, "edgeSize", temp*0.9)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
#모델 Training
model = train_word2vec("./trainTxt.txt", output_file = "w2vModel.bin",
threads=3, vectors=100, force = T)
read.vectors("./w2vModel.bin")
nearest_to(model,model[["냉장고"]], 20)
model[1]
read.vectors("./w2vModel.bin")
model[1]
model[1,]
model[-1,]
temp = cosineDist(model[-1,], model[-1,])
temp = temp[nchar(rownames(temp)) > 1, nchar(colnames(temp)) > 1]
temp[temp < 1.1] = 0
temp = temp[,colSums(temp)!=0]
temp = temp[rowSums(temp)!=0,]
net = network(temp, directed = FALSE)
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
set.edge.value(net, "edgeSize", temp*0.9)
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
#단어간 코사인 거리 구하기
temp = cosineDist(model, model)
#한글자 단어 삭제하기
temp = temp[nchar(rownames(temp)) > 1, nchar(colnames(temp)) > 1]
#Edge 개수 조절하기 (1~2 사이 값으로 세팅)
temp[temp < 1.1] = 0
#Node 개수 조절하기 (0인 값 제외)
temp = temp[,colSums(temp)!=0]
temp = temp[rowSums(temp)!=0,]
# Network Map을 그리기 위한 객체 만들기
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 0.8)
set.edge.value(net, "edgeSize", temp * 0.8)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
nearest_to(model,model[["냉장고"]], 20)
plot(nearest_to(model,model[["냉장고"]], 20))
barplot(nearest_to(model,model[["냉장고"]], 20))
nearest_to(model,model[["냉장고"]], 20)
nearest_to(model,model[["냉장고"]], 20)[1]
nearest_to(model,model[["냉장고"]], 20)
library(dplyr)
arrange(nearest_to(model,model[["냉장고"]], 20))
arrange(nearest_to(model,model[["냉장고"]], 20))
nearest_to(model,model[["냉장고"]], 20)
tt = nearest_to(model,model[["냉장고"]], 20)
tt
order(tt)
temp = cosineDist(model, model)
temp
tt = nearest_to(model,model[["냉장고"]], 20)
barplot(tt)
library(extrafont)
library(extrafont)
barplot(tt)
loadfonts(device="postscript")
barplot(tt)
barplot(tt, family = "AppleGothic" )
write_excel_csv(tt,"./tt.xlsx")
write_excel_csv(tt,"./tt.csv")
write_excel_csv(as.data.frame(tt),"./tt.xlsx")
write_excel_csv(as.data.frame(tt),"./tt.csv")
as.data.frame(tt)
write.csv(tt, "./tt.csv", row.names = T, fileEncoding = "EUC-KR")
write.csv(tt, "./tt.csv", row.names = T)
library(tm)
library(slam)
library(dplyr)
library(readr)
library(NLP4kec)
parsedData = text_parser(path = "/Users/kimnamyoun/TextConvert4TM/input/HomeApplication_cafe.xlsx"
,language = "ko"
,korDicPath = "./dictionary.txt")
parsedData = gsub(" ","  ",parsedData)
corp = VCorpus(VectorSource(parsedDataRe$pContent))
corp = VCorpus(VectorSource(parsedData))
corp = tm_map(corp, removePunctuation)
corp = tm_map(corp, removeNumbers)
corp = tm_map(corp, tolower)
corp = tm_map(corp, removeWords, c("있다", "하다","그렇다","되다","같다","가다","없다","보다","정도"))
for (j in seq(corp))
{
corp[[j]] <- gsub("lg", "엘지", corp[[j]])
corp[[j]] <- gsub("samsung", "삼성", corp[[j]])
}
corp = tm_map(corp, PlainTextDocument)
dtm = DocumentTermMatrix(corp, control=list(removeNumbers=FALSE, wordLengths=c(2,Inf)))
colnames(dtm) = trimws(colnames(dtm))
dtm = dtm[,nchar(colnames(dtm)) > 1]
tdm = TermDocumentMatrix(corp, control=list(removeNumbers=TRUE, wordLengths=c(2,Inf)))
dtm
dtm = removeSparseTerms(dtm, as.numeric(0.99))
dtm
dtm_df = as.data.frame(as.matrix(dtm))
View(dtm_df)
length(freq)
freq = colSums(as.matrix(dtm))
length(freq)
freq[head(order(-freq), 5)]
freq[head(order(freq), 10)]
wordDf = data.frame(word=names(freq), freq=freq)
library(ggplot2)
library(extrafont)
loadfonts(device="postscript")
ggplot(wordDf, aes(x=word, y=freq)) + geom_bar(stat = "identity")
ggplot(wordDf, aes(x=word, y=freq)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(family = "AppleGothic"))
ggplot(head(wordDf,10), aes(x=word, y=freq)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(family = "AppleGothic"))
ggplot(head(arrange(wordDf,-freq),20), aes(x=reorder(word,-freq), y=freq)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(family = "AppleGothic"))
#형태소 분석기 실행하기
parsedData = text_parser(path = "/Users/kimnamyoun/TextConvert4TM/input/HomeApplication_cafe.xlsx"
,language = "ko"
,korDicPath = "./dictionary.txt")
## 단어간 스페이스 하나 더 추가하기 ##
parsedData = gsub(" ","  ",parsedData)
library(topicmodels)
library(LDAvis)
library(servr)
library(readr)
library(tm)
library(slam)
library(dplyr)
library(NLP4kec)
parsedData = text_parser(path = "/Users/kimnamyoun/TextConvert4TM/input/HomeApplication_cafe.xlsx"
,language = "ko"
,korDicPath = "./dictionary.txt")
parsedData = gsub(" ","  ",parsedData)
corp=VCorpus(VectorSource(parsedData))
corp = tm_map(corp, removePunctuation)
corp = tm_map(corp, tolower)
corp = tm_map(corp, removeWords, c("있다", "하다","그렇다","되다","같다","가다","없다","보다","정도","000원","030원","주세요","어떻다"))
for (j in seq(corp))
{
corp[[j]] = gsub("lg", "엘지", corp[[j]])
corp[[j]] = gsub("samsung", "삼성", corp[[j]])
}
corp = tm_map(corp, PlainTextDocument)
dtm = DocumentTermMatrix(corp, control=list(removeNumbers=FALSE, wordLengths=c(2,Inf)))
colnames(dtm) = trimws(colnames(dtm))
dtm = dtm[,nchar(colnames(dtm)) > 1]
dtm = removeSparseTerms(dtm, as.numeric(0.997))
term_tfidf = tapply(dtm$v/row_sums(dtm)[dtm$i], dtm$j, mean) * log2(nDocs(dtm)/col_sums(dtm > 0))
boxplot(term_tfidf)
new_dtm = dtm[,term_tfidf >= 0.1]
new_dtm = new_dtm[row_sums(new_dtm) > 0,]
name = "HomeApplication"
SEED = 2017
k = 10 #클러스터 개수 세팅
lda_tm = LDA(new_dtm, control=list(seed=SEED), k)
term_topic = terms(lda_tm, 30)
write.table(term_topic, filePathName, sep=",", row.names=FALSE)
doc_topic = topics(lda_tm, 1)
doc_topic_df = as.data.frame(doc_topic)
doc_topic_df$rown = as.numeric(row.names(doc_topic_df))
View(doc_topic_df)
doc_Prob = posterior(lda_tm)$topics
doc_Prob_df = as.data.frame(doc_Prob)
doc_Prob_df$maxProb = apply(doc_Prob_df, 1, max)
doc_Prob_df$rown = doc_topic_df$rown
parsedData$rown = as.numeric(row.names(parsedData))
id_topic = merge(doc_topic_df, doc_Prob_df, by="rown")
id_topic = merge(id_topic, parsedData, by="rown", all.y = TRUE)
View(id_topic)
View(term_topic)
parsedData$rown = as.numeric(row.names(parsedData))
parsedData
parsedData = text_parser(path = "/Users/kimnamyoun/TextConvert4TM/input/HomeApplication_cafe.xlsx"
,language = "ko"
,korDicPath = "./dictionary.txt")
parsedData = gsub(" ","  ",parsedData)
parsedData
View(doc_Prob_df)
doc_Prob_df$parsedText = parsedData
View(doc_Prob_df)
parsedData = as.data.frame(parsedData)
View(parsedData)
doc_topic_df = as.data.frame(doc_topic)
doc_topic_df$rown = as.numeric(row.names(doc_topic_df))
doc_Prob = posterior(lda_tm)$topics
doc_Prob_df = as.data.frame(doc_Prob)
doc_Prob_df$maxProb = apply(doc_Prob_df, 1, max)
View(doc_Prob_df)
doc_Prob_df$rown = doc_topic_df$rown
parsedData$rown = as.numeric(row.names(parsedData))
id_topic = merge(doc_topic_df, doc_Prob_df, by="rown")
id_topic = merge(id_topic, parsedData, by="rown", all.y = TRUE)
id_topic = subset(id_topic,select=c("rown","id","doc_topic","maxProb"))
id_topic = subset(id_topic,select=c("rown","id","doc_topic","maxProb"))
View(id_topic)
View(id_topic)
id_topic = subset(id_topic,select=c("rown","id","doc_topic","maxProb"))
colnames(id_topic)
id_topic = subset(id_topic,select=c("rown","doc_topic","maxProb"))
# phi는 각 단어별 토픽에 포함될 확률값 입니다.
phi = posterior(lda_tm)$terms %>% as.matrix
# theta는 각 문서별 토픽에 포함될 확률값 입니다.
theta = posterior(lda_tm)$topics %>% as.matrix
# vocab는 전체 단어 리스트 입니다.
vocab = colnames(phi)
# 각 문서별 문서 길이를 구합니다.
doc_length = vector()
doc_topic_df=as.data.frame(doc_topic)
for( i in as.numeric(row.names(doc_topic_df))){
temp = corp[[i]]$content
doc_length = c(doc_length, nchar(temp[1]))
}
# 각 단어별 빈도수를 구합니다.
new_dtm_m = as.matrix(new_dtm)
freq_matrix = data.frame(ST = colnames(new_dtm_m),
Freq = colSums(new_dtm_m))
# 위에서 구한 값들을 파라메터 값으로 넘겨서 시각화를 하기 위한 데이터를 만들어 줍니다.
source("./createNamJson_v2.R")
json_lda = createNamJson(phi = phi, theta = theta,
vocab = vocab,
doc.length = doc_length,
term.frequency = freq_matrix$Freq,
#mds.method = jsPCA #canberraPCA가 작동 안할 때 사용
mds.method = canberraPCA
)
serVis(json_lda, open.browser = T) # MAC인 경우
