,family="AppleGothic")
#모델 Training
model = train_word2vec("./trainTxt.txt", output_file = "w2vModel.bin",
threads=3, vectors=100, force = T)
read.vectors("./w2vModel.bin")
nearest_to(model,model[["냉장고"]], 20)
model[1]
read.vectors("./w2vModel.bin")
model[1]
model[1,]
model[-1,]
temp = cosineDist(model[-1,], model[-1,])
temp = temp[nchar(rownames(temp)) > 1, nchar(colnames(temp)) > 1]
temp[temp < 1.1] = 0
temp = temp[,colSums(temp)!=0]
temp = temp[rowSums(temp)!=0,]
net = network(temp, directed = FALSE)
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
set.edge.value(net, "edgeSize", temp*0.9)
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
#단어간 코사인 거리 구하기
temp = cosineDist(model, model)
#한글자 단어 삭제하기
temp = temp[nchar(rownames(temp)) > 1, nchar(colnames(temp)) > 1]
#Edge 개수 조절하기 (1~2 사이 값으로 세팅)
temp[temp < 1.1] = 0
#Node 개수 조절하기 (0인 값 제외)
temp = temp[,colSums(temp)!=0]
temp = temp[rowSums(temp)!=0,]
# Network Map을 그리기 위한 객체 만들기
net = network(temp, directed = FALSE)
# Network의 betweenness값을 구하여 상위 10% 이상인 node에는 노란색 입혀주기
net %v% "mode" <- ifelse(betweenness(net) > quantile(betweenness(net), 0.9), "big", "small")
node_color = c("small" = "grey", "big" = "gold")
# Network edge size 값 설정하기 (단어간 상관계수 값 * 0.8)
set.edge.value(net, "edgeSize", temp * 0.8)
# Network Map 화면에 그리기
ggnet2(net # 네트워크 객체
,label=TRUE # 노드에 라벨 표현 여부
,label.size = 3 # 라벨 폰트 사이즈
,color = "mode" # 노드 색상 구준 기준
,palette = node_color # 노드 색상
,size = "degree" # 노드의 크기를 degree cetrality값에 따라 다르게 하기
,edge.size = "edgeSize" # 엣지의 굵기를 위에서 계산한 단어간 상관계수에 따라 다르게 하기
,family="AppleGothic")
nearest_to(model,model[["냉장고"]], 20)
plot(nearest_to(model,model[["냉장고"]], 20))
barplot(nearest_to(model,model[["냉장고"]], 20))
nearest_to(model,model[["냉장고"]], 20)
nearest_to(model,model[["냉장고"]], 20)[1]
nearest_to(model,model[["냉장고"]], 20)
library(dplyr)
arrange(nearest_to(model,model[["냉장고"]], 20))
arrange(nearest_to(model,model[["냉장고"]], 20))
nearest_to(model,model[["냉장고"]], 20)
tt = nearest_to(model,model[["냉장고"]], 20)
tt
order(tt)
temp = cosineDist(model, model)
temp
tt = nearest_to(model,model[["냉장고"]], 20)
barplot(tt)
library(extrafont)
library(extrafont)
barplot(tt)
loadfonts(device="postscript")
barplot(tt)
barplot(tt, family = "AppleGothic" )
write_excel_csv(tt,"./tt.xlsx")
write_excel_csv(tt,"./tt.csv")
write_excel_csv(as.data.frame(tt),"./tt.xlsx")
write_excel_csv(as.data.frame(tt),"./tt.csv")
as.data.frame(tt)
write.csv(tt, "./tt.csv", row.names = T, fileEncoding = "EUC-KR")
write.csv(tt, "./tt.csv", row.names = T)
library(tm)
library(slam)
library(dplyr)
library(readr)
library(NLP4kec)
parsedData = text_parser(path = "/Users/kimnamyoun/TextConvert4TM/input/HomeApplication_cafe.xlsx"
,language = "ko"
,korDicPath = "./dictionary.txt")
parsedData = gsub(" ","  ",parsedData)
corp = VCorpus(VectorSource(parsedDataRe$pContent))
corp = VCorpus(VectorSource(parsedData))
corp = tm_map(corp, removePunctuation)
corp = tm_map(corp, removeNumbers)
corp = tm_map(corp, tolower)
corp = tm_map(corp, removeWords, c("있다", "하다","그렇다","되다","같다","가다","없다","보다","정도"))
for (j in seq(corp))
{
corp[[j]] <- gsub("lg", "엘지", corp[[j]])
corp[[j]] <- gsub("samsung", "삼성", corp[[j]])
}
corp = tm_map(corp, PlainTextDocument)
dtm = DocumentTermMatrix(corp, control=list(removeNumbers=FALSE, wordLengths=c(2,Inf)))
colnames(dtm) = trimws(colnames(dtm))
dtm = dtm[,nchar(colnames(dtm)) > 1]
tdm = TermDocumentMatrix(corp, control=list(removeNumbers=TRUE, wordLengths=c(2,Inf)))
dtm
dtm = removeSparseTerms(dtm, as.numeric(0.99))
dtm
dtm_df = as.data.frame(as.matrix(dtm))
View(dtm_df)
length(freq)
freq = colSums(as.matrix(dtm))
length(freq)
freq[head(order(-freq), 5)]
freq[head(order(freq), 10)]
wordDf = data.frame(word=names(freq), freq=freq)
library(ggplot2)
library(extrafont)
loadfonts(device="postscript")
ggplot(wordDf, aes(x=word, y=freq)) + geom_bar(stat = "identity")
ggplot(wordDf, aes(x=word, y=freq)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(family = "AppleGothic"))
ggplot(head(wordDf,10), aes(x=word, y=freq)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(family = "AppleGothic"))
ggplot(head(arrange(wordDf,-freq),20), aes(x=reorder(word,-freq), y=freq)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(family = "AppleGothic"))
#형태소 분석기 실행하기
parsedData = text_parser(path = "/Users/kimnamyoun/TextConvert4TM/input/HomeApplication_cafe.xlsx"
,language = "ko"
,korDicPath = "./dictionary.txt")
## 단어간 스페이스 하나 더 추가하기 ##
parsedData = gsub(" ","  ",parsedData)
library(topicmodels)
library(LDAvis)
library(servr)
library(readr)
library(tm)
library(slam)
library(dplyr)
library(NLP4kec)
parsedData = text_parser(path = "/Users/kimnamyoun/TextConvert4TM/input/HomeApplication_cafe.xlsx"
,language = "ko"
,korDicPath = "./dictionary.txt")
parsedData = gsub(" ","  ",parsedData)
corp=VCorpus(VectorSource(parsedData))
corp = tm_map(corp, removePunctuation)
corp = tm_map(corp, tolower)
corp = tm_map(corp, removeWords, c("있다", "하다","그렇다","되다","같다","가다","없다","보다","정도","000원","030원","주세요","어떻다"))
for (j in seq(corp))
{
corp[[j]] = gsub("lg", "엘지", corp[[j]])
corp[[j]] = gsub("samsung", "삼성", corp[[j]])
}
corp = tm_map(corp, PlainTextDocument)
dtm = DocumentTermMatrix(corp, control=list(removeNumbers=FALSE, wordLengths=c(2,Inf)))
colnames(dtm) = trimws(colnames(dtm))
dtm = dtm[,nchar(colnames(dtm)) > 1]
dtm = removeSparseTerms(dtm, as.numeric(0.997))
term_tfidf = tapply(dtm$v/row_sums(dtm)[dtm$i], dtm$j, mean) * log2(nDocs(dtm)/col_sums(dtm > 0))
boxplot(term_tfidf)
new_dtm = dtm[,term_tfidf >= 0.1]
new_dtm = new_dtm[row_sums(new_dtm) > 0,]
name = "HomeApplication"
SEED = 2017
k = 10 #클러스터 개수 세팅
lda_tm = LDA(new_dtm, control=list(seed=SEED), k)
term_topic = terms(lda_tm, 30)
write.table(term_topic, filePathName, sep=",", row.names=FALSE)
doc_topic = topics(lda_tm, 1)
doc_topic_df = as.data.frame(doc_topic)
doc_topic_df$rown = as.numeric(row.names(doc_topic_df))
View(doc_topic_df)
doc_Prob = posterior(lda_tm)$topics
doc_Prob_df = as.data.frame(doc_Prob)
doc_Prob_df$maxProb = apply(doc_Prob_df, 1, max)
doc_Prob_df$rown = doc_topic_df$rown
parsedData$rown = as.numeric(row.names(parsedData))
id_topic = merge(doc_topic_df, doc_Prob_df, by="rown")
id_topic = merge(id_topic, parsedData, by="rown", all.y = TRUE)
View(id_topic)
View(term_topic)
parsedData$rown = as.numeric(row.names(parsedData))
parsedData
parsedData = text_parser(path = "/Users/kimnamyoun/TextConvert4TM/input/HomeApplication_cafe.xlsx"
,language = "ko"
,korDicPath = "./dictionary.txt")
parsedData = gsub(" ","  ",parsedData)
parsedData
View(doc_Prob_df)
doc_Prob_df$parsedText = parsedData
View(doc_Prob_df)
parsedData = as.data.frame(parsedData)
View(parsedData)
doc_topic_df = as.data.frame(doc_topic)
doc_topic_df$rown = as.numeric(row.names(doc_topic_df))
doc_Prob = posterior(lda_tm)$topics
doc_Prob_df = as.data.frame(doc_Prob)
doc_Prob_df$maxProb = apply(doc_Prob_df, 1, max)
View(doc_Prob_df)
doc_Prob_df$rown = doc_topic_df$rown
parsedData$rown = as.numeric(row.names(parsedData))
id_topic = merge(doc_topic_df, doc_Prob_df, by="rown")
id_topic = merge(id_topic, parsedData, by="rown", all.y = TRUE)
id_topic = subset(id_topic,select=c("rown","id","doc_topic","maxProb"))
id_topic = subset(id_topic,select=c("rown","id","doc_topic","maxProb"))
View(id_topic)
View(id_topic)
id_topic = subset(id_topic,select=c("rown","id","doc_topic","maxProb"))
colnames(id_topic)
id_topic = subset(id_topic,select=c("rown","doc_topic","maxProb"))
# phi는 각 단어별 토픽에 포함될 확률값 입니다.
phi = posterior(lda_tm)$terms %>% as.matrix
# theta는 각 문서별 토픽에 포함될 확률값 입니다.
theta = posterior(lda_tm)$topics %>% as.matrix
# vocab는 전체 단어 리스트 입니다.
vocab = colnames(phi)
# 각 문서별 문서 길이를 구합니다.
doc_length = vector()
doc_topic_df=as.data.frame(doc_topic)
for( i in as.numeric(row.names(doc_topic_df))){
temp = corp[[i]]$content
doc_length = c(doc_length, nchar(temp[1]))
}
# 각 단어별 빈도수를 구합니다.
new_dtm_m = as.matrix(new_dtm)
freq_matrix = data.frame(ST = colnames(new_dtm_m),
Freq = colSums(new_dtm_m))
# 위에서 구한 값들을 파라메터 값으로 넘겨서 시각화를 하기 위한 데이터를 만들어 줍니다.
source("./createNamJson_v2.R")
json_lda = createNamJson(phi = phi, theta = theta,
vocab = vocab,
doc.length = doc_length,
term.frequency = freq_matrix$Freq,
#mds.method = jsPCA #canberraPCA가 작동 안할 때 사용
mds.method = canberraPCA
)
serVis(json_lda, open.browser = T) # MAC인 경우
a = c(1,2,4)
b = list("test", 5, a)
mat = matrix( c(2, 4, 3, 1, 5, 7), # 데이터
nrow=2,         # 행의수
ncol=3,         # 열의수
byrow = TRUE)   # 행기준으로 만들기
dim(mat)
mat[1,2]
iris[,1] # 첫번째 열(column) 값 가져오기
iris[,2] # 두번째 열(column) 값 가져오기
iris[1,] # 첫번째 행(row) 값 가져오기
iris[2,] # 두번째 행(row) 값 가져오기
iris[,1:3] # 첫번째부터 세번째 열 가져오기
iris[1:3,] # 첫번째부터 세번째 행 가져오기
iris[4,2] # 네번째 행의 2번째 열 값 가져오기
iris$Sepal.Length
subset(iris, select = c(Sepal.Length))
iris[3,4]
subset(iris, iris$Sepal.Width > 4,  select = c(Sepal.Length)) # Subset 함수로 Sepal.Length, Sepal.Width 라는 이름을 갖는 열(column) 값 가져오기
install.packages("~/GitHub/NLP4kec_1.0.0.tgz", repos = NULL, type = .Platform$pkgType)
library(NLP4kec)
write.csv(iris, file = "./iris.csv", row.names = FALSE)
nrow(iris)
ncol(iris)
addRow = list(10, 20, 10, 20, "virginica")
iris = rbind(iris, addRow)
addCol = sample(1:151, 151)
addCol
colnames(iris)
colnames(iris)[6] = "ChangeColName" # 6번째 열이름 바꾸기
addCol = sample(1:151, 151)
iris = cbind(iris, addCol)
colnames(iris)[6] = "ChangeColName" # 6번째 열이름 바꾸기
colnames(iris) = c("a","b","c","d","e","f") # 모든 열이름 바꾸기
colnames(iris)[6] = "ChangeColName" # 6번째 열이름 바꾸기
colnames(iris)
colnames(iris) = c("a","b","c","d","e","f") # 모든 열이름 바꾸기
colnames(iris)
tapply(iris$Sepal.Length, iris$Species, mean) # Species별로 Sepal.Length의 평균 구하기
tapply(iris$Sepal.Length, iris$Species, mean) # Species별로 Sepal.Length의 평균 구하기
data("iris")
iris
tapply(iris$Sepal.Length, iris$Species, mean) # Species별로 Sepal.Length의 평균 구하기
addRow = list(10, 20, 10, 20, "virginica")
iris = rbind(iris, addRow)
addCol = sample(1:151, 151)
iris = cbind(iris, addCol)
colnames(iris)
colnames(iris)[6] = "ChangeColName" # 6번째 열이름 바꾸기
colnames(iris)
colnames(iris) = c("a","b","c","d","e","f") # 모든 열이름 바꾸기
colnames(iris)
tapply(iris$Sepal.Length, iris$Species, mean) # Species별로 Sepal.Length의 평균 구하기
data("iris")
iris
tapply(iris$Sepal.Length, iris$Species, mean) # Species별로 Sepal.Length의 평균 구하기
df1 = data.frame(id = c(1,2,3,4,5,6),
name=c("Jonh", "Jessica", "Tom","Rodrio","James","Alessia"))
df2 = data.frame(id=c(2,4,6,8),
location=c("Seoul","LA", "Paris","Rome"))
df1
df2
merge(df1, df2, by="id")
merge(df1, df2, all.x = TRUE)
merge(df1, df2, all.y = TRUE)
sentence = c("I like an apple.")
grepl("like", sentence)
grep("like", sentence)
gsub("like", "hate", sentence)
paste(sentence, "And I have the apple.")
substr(sentence, 4, 7)
substr(sentence, 1, 6) = "I hate"
sentence2 = c("I", "like", "an", "apple.")
grep("like", sentence)
sentence2 = c("I", "like", "an", "apple.")
grep("like", sentence2)
sentence = c("I like an apple.")
grepl("like", sentence)
grep("like", sentence)
sentence2 = c("I", "like", "an", "apple.")
grep("like", sentence2)
substr(sentence, 4, 7)
substr(sentence, 1, 6) = "I hate"
regexpr("like",sentence)
gregexpr("a", sentence)
sentence = c("I like an apple.")
gregexpr("a", sentence)
substr(sentence, 1, 6) = "I hate" # 1번째 문자에서 6문자 사이의 문자열 바꾸기
regexpr("like",sentence)
regexpr("hate",sentence)
gregexpr("a", sentence)
split = strsplit(sentence, " ")
split
b = list("test", 5, a)
b
split = unlist(split) # Vector 형식으로 바꿔주기
split
grep("an", split)
meltTest = melt(data = Cars93,
id.vars = "Type",
measure.vars = c("MPG.city", "MPG.highway"))
library(reshape2)
meltTest = melt(data = Cars93,
id.vars = "Type",
measure.vars = c("MPG.city", "MPG.highway"))
data(Cars93)
Cars93
library(MASS)
data(Cars93)
Cars93
meltTest = melt(data = Cars93,
id.vars = "Type",
measure.vars = c("MPG.city", "MPG.highway"))
head(meltTest)
a = c(1,8,5)
#1. if문
if(length(a) > 1){
mean(a)
}
length(iris[,1])
length(iris[1,])
a = c(1,8,5)
if(length(a) > 1){
mean(a)
}
if(length(a) > 4){
mean(a)
}
if(length(a) > 4){
mean(a)
} else {
a
}
#2. else 문
if(length(a) > 4){
mean(a)
} else {
print("조건에 맞지 않습니다.")
}
ifelse(length(a) > 1, mean(a), "조건에 맞지 않습니다.")
sum=0
for (i in 1:10){
sum = sum + i
}
sum
i = 1
while(i<=10){
print(i*3)
i = i+1
}
i
#5.while 문 (ex. 3의 배수만 출력하기)
i = 1
while(i<=10){
print(i*3)
i = i+1
}
sum=0
for (i in 1:10){
sum = sum * i
}
sum
sum=1
for (i in 1:10){
sum = sum * i
}
sum
5 %any% 2
5 %/% 2
5 %/% 3
5 %% 3
5 %% 2
1 %% 2
2 %% 2
x = 0
for(i in 1:20){
if((i %% 2) == 0){
x = x + i
}
}
x
myFunction = function(data, company){
temp = subset(data, data$Manufacturer == company)
sumPrice = sum(temp$Price)
return(sumPrice)
}
aa = myFunction(Cars93, "Acura")
aa
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count")
library(ggplot2)
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count")
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count") + labs(x="Car Type") + theme_minimal()
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count") + labs(x="Car Type") +
ggtitle("자동차 타입별 건수") + theme(plot.title = element_text(hjust = 0.1, size = 25)) # 차트에 제목 넣기
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count") + labs(x="Car Type") +
ggtitle("자동차 타입별 건수") + theme(plot.title = element_text(hjust = 0.1, size = 25), axis.text.x = element_text(family = "AppleGothic")) # 차트에 제목 넣기
library(extrafont)
loadfonts(device="postscript")
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count") + labs(x="Car Type") +
ggtitle("자동차 타입별 건수") + theme(plot.title = element_text(hjust = 0.1, size = 25), axis.text.x = element_text(family = "AppleGothic")) # 차트에 제목 넣기
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count") + labs(x="Car Type") +
ggtitle("자동차 타입별 건수") + theme(plot.title = element_text(hjust = 0.1, size = 25))+ theme(axis.text.x = element_text(family = "AppleGothic")) # 차트에 제목 넣기
library(extrafont)
loadfonts(device="postscript")
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count") + labs(x="Car Type") +
ggtitle("자동차 타입별 건수") + theme(plot.title = element_text(hjust = 0.1, size = 25))+ theme(axis.text.x = element_text(family = "AppleGothic")) # 차트에 제목 넣기
font_import(pattern = "AppleGothic")
library(extrafont)
loadfonts(device="postscript")
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count") + labs(x="Car Type") +
ggtitle("자동차 타입별 건수") + theme(plot.title = element_text(hjust = 0.1, size = 25))+ theme(axis.text= element_text(family = "AppleGothic")) # 차트에 제목 넣기
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count") + labs(x="Car Type") +
ggtitle("자동차 타입별 건수") + theme(plot.title = element_text(hjust = 0.1, size = 25, family = "AppleGothic")) # 차트에 제목 넣기
ggplot(Cars93, aes(x=Type, fill=Origin)) + geom_bar(stat = "count")
ggplot(Cars93, aes(x=Type, fill=Origin)) + geom_bar(stat = "count", position = "dodge") # Stack 하지 않기
mpg_temp = Cars93 %>% group_by(Type) %>% summarise(avgPrice = mean(Price))
library(dplyr)
mpg_temp = Cars93 %>% group_by(Type) %>% summarise(avgPrice = mean(Price))
ggplot(mpg_temp, aes(x=Type, y=avgPrice)) + geom_bar(stat = "identity") #데이터프레임 내 값 그대로
ggplot(Cars93, aes(x=Type)) + geom_bar(stat = "count") + labs(x="Car Type") +
ggtitle("The Count by Car Type") + theme(plot.title = element_text(hjust = 0.1, size = 25)) # 차트에 제목 넣기
ggplot(Cars93, aes(x=Type, fill=Origin)) + geom_bar(stat = "count")
mpg_temp = Cars93 %>% group_by(Type) %>% summarise(avgPrice = mean(Price))
ggplot(mpg_temp, aes(x=Type, y=avgPrice)) + geom_bar(stat = "identity") #데이터프레임 내 값 그대로
df2 = Cars93 %>% group_by(Type, Origin) %>% summarise(n=n()) %>%
mutate(ratio = n/sum(n))
ggplot(df2, aes(x=Type, y=ratio, fill=Origin)) + geom_bar(stat = "identity")
df2
ggplot(Cars93, aes(x=MPG.city, y=Price)) + geom_point(stat = "identity")
ggplot(Cars93, aes(x=MPG.city, y=Price)) + geom_point(shape=3) # 점모양 바꾸기
ggplot(Cars93, aes(x=MPG.city, y=Price, label = Manufacturer)) + geom_text(size=3) # 점 대신 라벨값 보여주기
ggplot(Cars93, aes(x=MPG.city, y=Price)) + geom_point(shape=2) + geom_smooth(method=lm) # 선형식 그리기
ggplot(Cars93, aes(x=MPG.city, y=Price)) + geom_point(shape=2) + geom_smooth() #다항식 그리기
ggplot(Cars93, aes(x=MPG.city, y=Price, color=factor(Manufacturer))) + geom_point(shape=2) #특정 범주형 값 별로 색깔 다르게 하기
ggplot(Cars93, aes(x=MPG.city, y=Price, color=factor(Manufacturer), size=EngineSize)) + geom_point(shape=18) #특정 범주형 값 별로 색깔/크기 다르게 하기
ggplot(Cars93, aes(x=factor(Manufacturer), y=Price)) + geom_boxplot() + theme(axis.text.x=element_text(angle = 45, hjust = 1))
ggplot(Cars93, aes(x=factor(Type), y=Price, fill=factor(Origin))) + geom_boxplot()
data("economics")
economics
ggplot(economics, aes(x=date, y=pop)) + geom_line(stat = "identity")
ggplot(economics, aes(x=pop, y=unemploy)) + geom_point()
ggplot(economics, aes(x=pop, y=unemploy)) + geom_point() +
scale_x_continuous(breaks = seq(200000, max(economics$pop), 10000)) +
theme(axis.text.x=element_text(angle = 45, hjust = 1))
economics$year = substr(economics$date,1,4)
ggplot(economics, aes(x=pop, y=unemploy, color=factor(year))) + geom_point()
ggplot(economics, aes(x=pop, y=unemploy)) + geom_point() +
scale_x_continuous(breaks = seq(200000, max(economics$pop), 10000)) +
theme(axis.text.x=element_text(angle = 45, hjust = 1))
economics$year = substr(economics$date,1,4)
ggplot(economics, aes(x=pop, y=unemploy, color=factor(year))) + geom_point()
ggplot(economics, aes(x=pop, y=unemploy)) + geom_point()
ggplot(economics, aes(x=pop, y=unemploy)) + geom_point() +
scale_x_continuous(breaks = seq(200000, max(economics$pop), 10000)) +
theme(axis.text.x=element_text(angle = 45, hjust = 1))
economics$year = substr(economics$date,1,4)
ggplot(economics, aes(x=pop, y=unemploy, color=factor(year))) + geom_point()
library(corrplot)
install.packages("corrplot")
library(corrplot)
subCars93 = Cars93 %>% dpselect(Price, MPG.city, MPG.highway, EngineSize)
subCars93 = Cars93 %>% select(Price, MPG.city, MPG.highway, EngineSize)
plot(subCars93)
corrplot(corDf)
corDf = cor(subCars93)
corrplot(corDf)
subCars93 = Cars93 %>% select(Price, MPG.city, MPG.highway, EngineSize)
plot(subCars93)
corrplot(corDf)
corrplot(corDf, method = "shade", tl.srt=45)
corrplot(corDf, method = "shade", tl.srt=45, addCoef.col = "black", order="AOE")
corrplot(corDf, method = "shade", tl.srt=45, addCoef.col = "black", order="AOE", type = "lower")
remove.packages("NLP4kec")
install.packages("~/Downloads/NLP4kec_1.0.0.tgz", repos = NULL, type = .Platform$pkgType)
library("NLP4kec", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
